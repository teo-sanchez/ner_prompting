title: "Name Entity Recognition for text-to-image prompting"
description: > 
  Project to train a evaluate a name entity recognition model to analyzing text-to-image prompts.

  The entities comprise 17 categories 7 main categories and 11 subcategories, extracted from a topic analysis made with [BERTopic](https://maartengr.github.io/BERTopic/index.html).
  The topic analysis can be explored [the following visualization](https://teo-sanchez.github.io/projects/prompting_map.html).

  ├── medium/
  │   ├── photography
  │   ├── painting
  │   ├── rendering
  │   └── illustration
  ├── influence/
  │   ├── artist
  │   ├── genre
  │   ├── artwork
  │   └── repository
  ├── context/
  │   ├── era
  │   ├── weather
  │   └── mood
  ├── color
  ├── light
  ├── detail
  └── composition
  Prompt data are from the [diffusionDB](https://poloclub.github.io/diffusiondb/) database and were annotated by hand using [Prodigy](https://prodi.gy/).


# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  config_pretrain: "config_cpu_pretrain.cfg"
  config_train: "config_cpu_train.cfg"
  name: "ner_prompting"
  version: "0.0.3"
  train: "ner_prompting_training"
  dev: "ner_prompting_eval"
  company: selas-ai

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "training", "configs", "scripts", "corpus", "packages", "hub"]

# Assets that should be downloaded or available in the directory. We're shipping
# them with the project, so they won't have to be downloaded. But the
# 'project assets' command still lets you verify that the checksums match.
assets:
  - dest: "assets/diffusiondb_raw_prompts.jsonl"
    url: "https://storage.googleapis.com/selas-api/diffusion_raw_prompts.jsonl"
    description: "JSONL-formatted of all diffusionDB prompts"
  - dest: "assets/ner_prompting.jsonl"
    url: "https://storage.googleapis.com/selas-api/ner_prompting.jsonl"
    description: "JSONL-formatted development data exported from Prodigy, annotated with 17 entities"

# Workflows are sequences of commands (see below) executed in order. You can
# run them via "spacy project run [workflow]". If a commands's inputs/outputs
# haven't changed, it won't be re-run.
workflows:
  all:
    - preprocess
    - pretrain
    - train
    - evaluate
    - package
    - push_to_hub

commands:
  - name: "install"
    help: "Install dependencies, log in to Hugging Face and download a model"
    script:
      - "pip install -r requirements.txt"
      - "huggingface-cli login"

  # Replace this with any code to train a pipeline
  - name: "preprocess"
    help: "Convert the data to spaCy's binary format"
    script:
      - "python scripts/eval_split.py --jsonl_path assets/ner_prompting.jsonl --split_ratio 0.2"
      - "python scripts/preprocess.py assets/${vars.train}.jsonl corpus/${vars.train}.spacy"
      - "python scripts/preprocess.py assets/${vars.dev}.jsonl corpus/${vars.dev}.spacy"
    deps:
      - "assets/ner_prompting.jsonl"
      - "scripts/preprocess.py"
      - "scripts/eval_split.py"
    outputs:
      - "corpus/${vars.train}.spacy"
      - "corpus/${vars.dev}.spacy"

  - name: "pretrain"
    help: "Pretrain the embedding on all prompts"
    script:
      # - "wget https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl training/."
      # - "pip install training/en_core_web_lg-3.4.1-py3-none-any.whl"
      # - "rm training/en_core_web_lg-3.4.1-py3-none-any.whl"
      - "spacy pretrain configs/${vars.config_pretrain} training/pretrain_embedding --paths.raw_text assets/diffusiondb_raw_prompts.jsonl -g 0 --resume-path training/pretrain_embedding/model50.bin --epoch-resume 50"

  - name: "train"
    help: "Train a named entity recognition model"
    script:
      - "spacy train configs/${vars.config_train} --output training/ --paths.train corpus/${vars.train}.spacy --paths.dev corpus/${vars.dev}.spacy --gpu-id 0 --verbose "
    deps:
      - "corpus/${vars.train}.spacy"
      - "corpus/${vars.dev}.spacy"
    outputs:
      - "training/model-best"

  - name: "evaluate"
    help: "Evaluate the model and export metrics"
    script:
      - "python -m spacy evaluate training/model-best corpus/${vars.dev}.spacy --output training/metrics.json"
    deps:
      - "corpus/${vars.dev}.spacy"
      - "training/model-best"
    outputs:
      - "training/metrics.json"

  # Create the package using --build wheel
  - name: package
    help: "Package the trained model so it can be installed"
    script:
      - "python -m spacy package training/model-best packages --name ${vars.name} --version ${vars.version} --force --build wheel"
    deps:
      - "training/model-best"
    outputs_no_cache:
      - "packages/en_${vars.name}-${vars.version}/dist/en_${vars.name}-${vars.version}-py3-none-any.whl"

  # Push the package to the Hub
  - name: push_to_hub
    help: Push the model to the Hub
    script:
      - "python -m spacy huggingface-hub push packages/en_${vars.name}-${vars.version}/dist/en_${vars.name}-${vars.version}-py3-none-any.whl"
    deps:
      - "packages/en_${vars.name}-${vars.version}"
